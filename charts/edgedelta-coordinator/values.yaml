# Default values for edgedelta-coordinator.

# Use either apiKey or secretApiKey.value but NOT both to provide API Key to Agent
apiKey: ""

secretApiKey:
  name: "ed-api-key"
  key: "ed-api-key"
  value: ""
  enable: false # set true when creating template from charts

# Predefined environment variables
# See: https://docs.edgedelta.com/helm-values/

storePort: ""
profilerPort: ""
promPort: ""
httpProxy: ""
httpsProxy: ""
noProxy: ""
edBackendDisabled: ""
edTagOverride: ""
edClusterName: ""
edSuppressionMode: ""
edSkipConfDownload: ""
edWorkflows: ""
edWorkflowPrefixes: ""
edDisableLeaderElection: ""
edTraceFiles: ""
edAggregatorTraceFiles: ""
edSkipTlsVerify: ""
edConfigContent: ""
goMemLimit: ""

edEnableControllerDiscovery: true

# skipping adding common labels for helm charts into direct helm to k8s yaml file creation.
skipCommonLabels: false

# custom tags are comma separated key:val pairs. these are going to be attached to all outgoing data from agents to configured destination(s).
edCustomTags: ""

# Volume props will be used for mounting certain volume(s) to the given path(s) for the agents
# volumeProps:
#   volumeMounts:
#     - mountPath: /var/lib/kubelet
#       name: varlibkubelet
#       readOnly: true
#   volumes:
#     - hostPath:
#         path: /var/lib/kubelet
#         type: ""
#       name: varlibkubelet

# Custom labels:

# labels:
#   sample-label-key: sample-label-value

# Custom environment variables:

# envs:
#  - name: sample-var
#    value: sample-value

# Custom secret environment variables:
# Use only lowercase alphabetic and - characters in secretKeyRef name and key fields, otherwise helm deploys the release but throws an obscure error about DNS-1123 subdomain format

# secrets:
#  - name: sampleSecretVar
#    secretKeyRef:
#      name: sample-k8-secret-name
#      key: sample-k8s-secret-subkey

# Create secrets with below command:
# kubectl create secret generic sample-k8-secret-name --namespace=edgedelta --from-literal=sample-k8s-secret-subkey="SECRET_VALUE"

# Resource constraints
annotations: {}
resources:
  limits:
    cpu: 2000m
    memory: 2Gi
  requests:
    cpu: 200m
    memory: 256Mi

tolerations: {}
nodeSelector: {}
priorityClassName: ""
# topologySpreadConstraints -- Topology spread constraints for coordinator agent
topologySpreadConstraints: []
# - maxSkew: 1
#   topologyKey: topology.kubernetes.io/zone
#   whenUnsatisfiable: ScheduleAnyway
#   labelSelector:
#     matchLabels:
#       edgedelta/agent-type: processor

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1

coordinatorProps:
  port: 5555
  serviceDNSSuffix: svc.cluster.local

# Helm overrides
repository: gcr.io/edgedelta
image:
  name: agent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""
  # Overrides full image (with url and version/tag) if not empty
  # example: gcr.io/edgedelta/agent@sha256:0180ff40f52528d7462200c40fae8aff3bdb83289ac19ce823a3fcb1c40c9ad9
  fullPath: ""
  pullPolicy: IfNotPresent
  pullSecrets: []

# nameOverride -- Override the name of resources.
nameOverride: ""
# fullnameOverride -- Override the full name of resources.
fullnameOverride: ""

# networkPolicy -- Manage NetworkPolicy
networkPolicy:
  # networkPolicy.enabled -- If true, create NetworkPolicy for DaemonSet
  enabled: false
  # networkPolicy.type -- Type of the network policy to use.
  # Can be:
  # * cilium     for cilium.io/v2/CiliumNetworkPolicy
  type: cilium
  cilium:
    # networkPolicy.cilium.dnsSelector -- Cilium selector of the DNSâ€¯server entity
    # @default -- kube-dns in namespace kube-system
    dnsSelector:
      toEndpoints:
        - matchLabels:
            "k8s:io.kubernetes.pod.namespace": kube-system
            "k8s:k8s-app": kube-dns

    # networkPolicy.cilium.customEndpoints -- Custom endpoint addresses for egress traffic
    #
    # customEndpoints:
    #   toFQDNs:
    #     - matchName: "api.edgedelta.com"
    #     - matchPattern: "*.s3.us-east-1.amazonaws.com"
    #   toCIDR:
    #     - 192.168.1.0/24
    #   toServices:
    #     - k8sService:
    #         namespace: default
    #         serviceName: customservice
    #   toPorts:
    #     - ports:
    #         - port: "443"
    #           protocol: TCP

instructionURL: "https://app.edgedelta.com"

serviceAccount:
  # serviceAccount.annotations -- Annotations for the service account
  labels: {}
  # serviceAccount.labels -- Labels for the service account
  annotations: {}

podSecurity:
  securityContextConstraints:
    # podSecurity.securityContextConstraints.create -- If true, create a SecurityContextConstraints resource for pods
    create: false

  # podSecurity.capabilities -- Allowed capabilities
  capabilities:
    - SYS_ADMIN
    - SYS_RESOURCE
    - SYS_PTRACE
    - NET_ADMIN
    - NET_BROADCAST
    - NET_RAW
    - IPC_LOCK
    - CHOWN
    - AUDIT_CONTROL
    - AUDIT_READ
    - DAC_READ_SEARCH

  # podSecurity.volumes -- Allowed volumes types
  volumes:
    - configMap
    - downwardAPI
    - emptyDir
    - hostPath
    - secret

  # podSecurity.seLinuxContext -- Provide seLinuxContext configuration for SCC
  # @default -- Must run as spc_t (For reference, please refer here: https://access.redhat.com/solutions/7025337)
  seLinuxContext:
    type: MustRunAs
    seLinuxOptions:
      user: system_u
      role: system_r
      type: spc_t
      level: s0

  # podSecurity.seccompProfiles -- Allowed seccomp profiles
  seccompProfiles:
    - "runtime/default"

  apparmor:
    # podSecurity.apparmor.enabled -- If true, it will enable apparmor for the pods
    enabled: false
    # podSecurity.apparmor.profile -- If apparmor enabled, it will be the profile for apparmor enforcement for the pods
    profile: "unconfined"

  # podSecurity.privileged -- If true, allow to run privileged containers. If eBPF tracer is enabled, this will be automatically true
  privileged: false